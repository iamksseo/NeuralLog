{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamksseo/NeuralLog/blob/main/test/jack_neurallog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a0r9TEkVUBQ"
      },
      "source": [
        "```\n",
        "@inproceedings{le2021log,\n",
        "  title={Log-based anomaly detection without log parsing},\n",
        "  author={Le, Van-Hoang and Zhang, Hongyu},\n",
        "  booktitle={2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)},\n",
        "  pages={492--504},\n",
        "  year={2021},\n",
        "  organization={IEEE}\n",
        "}\n",
        "\n",
        "@INPROCEEDINGS{9534113,\n",
        "  author={Guo, Haixuan and Yuan, Shuhan and Wu, Xintao},\n",
        "  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, \n",
        "  title={LogBERT: Log Anomaly Detection via BERT}, \n",
        "  year={2021},\n",
        "  volume={},\n",
        "  number={},\n",
        "  pages={1-8},\n",
        "  doi={10.1109/IJCNN52387.2021.9534113}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rKYv2uadk0e"
      },
      "source": [
        "mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jfh1754VJv0",
        "outputId": "03367d89-c110-4582-cb59-26ef42552263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh6z8r1Odp0x"
      },
      "source": [
        "install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gQoJKLNFi99k",
        "outputId": "ce9cb35f-8331-47ab-9927-03d6e2aee3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ml_data/neurallog\n",
            "data  demo  docs  LICENSE  logs  neurallog  README.md  requirements.txt  test\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy~=1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 7.5 MB/s \n",
            "\u001b[?25hCollecting scikit-learn~=0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 94.1 MB/s \n",
            "\u001b[?25hCollecting transformers~=4.19.2\n",
            "  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 52.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.4.0\n",
            "  Downloading tensorflow-2.4.4-cp37-cp37m-manylinux2010_x86_64.whl (394.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.5 MB 40 kB/s \n",
            "\u001b[?25hCollecting tf-models-official~=2.4.0\n",
            "  Downloading tf_models_official-2.4.0-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas~=1.3.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.3.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=0.24.2->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=0.24.2->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=0.24.2->-r requirements.txt (line 2)) (1.7.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.19.2->-r requirements.txt (line 3)) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 64.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.19.2->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.19.2->-r requirements.txt (line 3)) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers~=4.19.2->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers~=4.19.2->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers~=4.19.2->-r requirements.txt (line 3)) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers~=4.19.2->-r requirements.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (0.37.1)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (3.17.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (0.2.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 48.1 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 40.1 MB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4.0->-r requirements.txt (line 4)) (1.1.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.12.11)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (2.0.4)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (4.6.0.66)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.29.32)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.5.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.21.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (4.6.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.5.12)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official~=2.4.0->-r requirements.txt (line 5)) (4.1.3)\n",
            "Collecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 74.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.3.5->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.3.5->-r requirements.txt (line 6)) (2022.2.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.31.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.56.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (4.2.4)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (2022.6.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (6.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers~=4.19.2->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=4.19.2->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers~=4.19.2->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->-r requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow~=2.4.0->-r requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow~=2.4.0->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers~=4.19.2->-r requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow~=2.4.0->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.1.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (1.9.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (5.9.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.3.5.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official~=2.4.0->-r requirements.txt (line 5)) (0.10.2)\n",
            "Building wheels for collected packages: py-cpuinfo, wrapt, seqeval\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=9515d7ab41de4ed39ded665e73b3c407ed34c6a2bdef00a1df6aeda39aee8ba8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68716 sha256=ab7de96bf52282969eb0d4809b2f53f1f7ba23ecd3dade506240272007f1c402\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=dbd07ce98e4b87798c25ffe8736598bea83788733c51d5605aea2969ecc20748\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built py-cpuinfo wrapt seqeval\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, scikit-learn, h5py, gast, flatbuffers, tokenizers, tf-slim, tensorflow-model-optimization, tensorflow-addons, tensorflow, seqeval, sentencepiece, py-cpuinfo, huggingface-hub, dataclasses, transformers, tf-models-official\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.47.0\n",
            "    Uninstalling grpcio-1.47.0:\n",
            "      Successfully uninstalled grpcio-1.47.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.2.0\n",
            "    Uninstalling absl-py-1.2.0:\n",
            "      Successfully uninstalled absl-py-1.2.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 dataclasses-0.6 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 huggingface-hub-0.9.1 numpy-1.19.5 py-cpuinfo-8.0.0 scikit-learn-0.24.2 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-2.4.4 tensorflow-addons-0.17.1 tensorflow-estimator-2.4.0 tensorflow-model-optimization-0.7.3 tf-models-official-2.4.0 tf-slim-1.1.0 tokenizers-0.12.1 transformers-4.19.4 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!pwd\n",
        "#import os\n",
        "#os.chdir(\"/content/drive/MyDrive/ml_data/neurallog\")\n",
        "%cd /content/drive/MyDrive/ml_data/neurallog\n",
        "!ls\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg4mwLf-GFLT",
        "outputId": "e4d42cbe-8e29-4620-ae2c-43ff44882e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ml_data/neurallog/demo\n",
            "2022-08-27 05:23:20.958354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.4.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n",
            "2022-08-27 05:23:26.366834: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-08-27 05:23:26.369238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-08-27 05:23:26.437291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:26.437906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-08-27 05:23:26.437944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-08-27 05:23:26.492341: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-08-27 05:23:26.492499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-08-27 05:23:26.517994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-08-27 05:23:26.535095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-08-27 05:23:26.747139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-08-27 05:23:26.765607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-08-27 05:23:26.771322: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-08-27 05:23:26.771500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:26.772160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:26.772726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-08-27 05:23:26.773093: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-08-27 05:23:26.773230: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-08-27 05:23:26.773406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:26.774015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-08-27 05:23:26.774052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-08-27 05:23:26.774109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-08-27 05:23:26.774134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-08-27 05:23:26.774159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-08-27 05:23:26.774186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-08-27 05:23:26.774213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-08-27 05:23:26.774235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-08-27 05:23:26.774264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-08-27 05:23:26.774352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:26.774954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:26.775486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-08-27 05:23:26.775530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-08-27 05:23:27.520037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-27 05:23:27.520102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2022-08-27 05:23:27.520121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2022-08-27 05:23:27.520333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:27.521008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:27.521621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-27 05:23:27.522154: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-08-27 05:23:27.522201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Downloading: 100% 0.99M/0.99M [00:00<00:00, 2.80MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 1.47MB/s]\n",
            "Downloading: 100% 665/665 [00:00<00:00, 737kB/s]\n",
            "Downloading: 100% 475M/475M [00:06<00:00, 71.7MB/s]\n",
            "2022-08-27 05:23:38.361137: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2022-08-27 05:23:38.444672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-08-27 05:23:40.151508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "All model checkpoint layers were used when initializing TFGPT2Model.\n",
            "\n",
            "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 1.24MB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 23.7kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 470kB/s]\n",
            "Downloading: 100% 511M/511M [00:07<00:00, 69.4MB/s]\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "Downloading: 100% 878k/878k [00:00<00:00, 2.40MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 1.46MB/s]\n",
            "Downloading: 100% 481/481 [00:00<00:00, 259kB/s]\n",
            "Downloading: 100% 627M/627M [00:22<00:00, 29.8MB/s]\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            "Loading ../logs/BGL.log\n",
            "Loaded 4747963 lines!\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Loading 99.52% - 580 unique logs\n",
            "last train index: 3798360\n",
            "Total failure logs: 17340\n",
            "Total: 150979 instances, 20254 anomaly, 130725 normal\n",
            "Train: 103500 instances, 17250 anomaly, 86250 normal\n",
            "Test: 47479 instances, 3004 anomaly, 44475 normal\n",
            "\n",
            "Number of training samples: 93150 - Number of validating samples: 10350\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 75, 768)]         0         \n",
            "_________________________________________________________________\n",
            "position_embedding (Position (None, 75, 768)           0         \n",
            "_________________________________________________________________\n",
            "transformer_block (Transform (None, 75, 768)           31491584  \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dropout_113 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                24608     \n",
            "_________________________________________________________________\n",
            "dropout_114 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 31,516,258\n",
            "Trainable params: 31,516,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1839: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "2022-08-27 05:28:39.834862: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-08-27 05:28:39.842517: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "Epoch 1/10\n",
            "363/363 [==============================] - 396s 1s/step - loss: 0.4858 - accuracy: 0.8155 - val_loss: 0.3156 - val_accuracy: 0.8263\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.82627, saving model to bgl_transformer.hdf5\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 394s 1s/step - loss: 0.2560 - accuracy: 0.8890 - val_loss: 0.1044 - val_accuracy: 0.9742\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.82627 to 0.97422, saving model to bgl_transformer.hdf5\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 391s 1s/step - loss: 0.1027 - accuracy: 0.9730 - val_loss: 0.0659 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.97422 to 0.98379, saving model to bgl_transformer.hdf5\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 393s 1s/step - loss: 0.0633 - accuracy: 0.9837 - val_loss: 0.0461 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.98379 to 0.98535, saving model to bgl_transformer.hdf5\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 390s 1s/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.0239 - val_accuracy: 0.9923\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.98535 to 0.99229, saving model to bgl_transformer.hdf5\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 391s 1s/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.0163 - val_accuracy: 0.9945\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.99229 to 0.99453, saving model to bgl_transformer.hdf5\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 390s 1s/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0132 - val_accuracy: 0.9956\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99453 to 0.99561, saving model to bgl_transformer.hdf5\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 390s 1s/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0073 - val_accuracy: 0.9982\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.99561 to 0.99824, saving model to bgl_transformer.hdf5\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 391s 1s/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99824 to 0.99873, saving model to bgl_transformer.hdf5\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 390s 1s/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0057 - val_accuracy: 0.9982\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.99873\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1900: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
            "/bin/bash: line 1:   470 Killed                  python NeuralLog.py\n",
            "\n",
            "real\t71m8.621s\n",
            "user\t56m54.061s\n",
            "sys\t3m51.040s\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "#os.chdir(\"/content/drive/MyDrive/ml_data/neurallog/demo\")\n",
        "\n",
        "%cd /content/drive/MyDrive/ml_data/neurallog/demo\n",
        "!time python NeuralLog.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxhyvB9_cTAR"
      },
      "outputs": [],
      "source": [
        "from neurallog import data_loader\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ml_data/neurallog/data/raw/BGL.log\"\n",
        "emb_dir = \"/content/drive/MyDrive/ml_data/neurallog/data/embeddings/BGL\"\n",
        "\n",
        "(x_tr, y_tr), (x_te, y_te) = data_loader.load_Supercomputers(\n",
        "     log_file, train_ratio=0.8, windows_size=20,\n",
        "     step_size=5, e_type='bert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGrsUeQ1jSln"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq-XjIK3eE8t"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "jack_neurallog.ipynb",
      "provenance": [],
      "mount_file_id": "1kaafiDNcKLI_XFKGkGUalWpVs1srXQ1B",
      "authorship_tag": "ABX9TyN5lLXmkdiEBltRLwhJWvfc",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}