{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamksseo/NeuralLog/blob/main/test/west_colab_BGL_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "@inproceedings{le2021log,\n",
        "  title={Log-based anomaly detection without log parsing},\n",
        "  author={Le, Van-Hoang and Zhang, Hongyu},\n",
        "  booktitle={2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)},\n",
        "  pages={492--504},\n",
        "  year={2021},\n",
        "  organization={IEEE}\n",
        "}\n",
        "\n",
        "@INPROCEEDINGS{9534113,\n",
        "  author={Guo, Haixuan and Yuan, Shuhan and Wu, Xintao},\n",
        "  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, \n",
        "  title={LogBERT: Log Anomaly Detection via BERT}, \n",
        "  year={2021},\n",
        "  volume={},\n",
        "  number={},\n",
        "  pages={1-8},\n",
        "  doi={10.1109/IJCNN52387.2021.9534113}\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "tEY4vn6nGn3p"
      },
      "id": "tEY4vn6nGn3p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup env (runtime=GPU)\n",
        "\n",
        "* make `upload_colab.tar.gz` in local\n",
        "```\n",
        "git clone https://github.com/iamksseo/NeuralLog.git\n",
        "tar cvfz upload_colab.tar.gz NeuralLog/neurallog NeuralLog/demo NeuralLog/requirements_colab_0826.txt\n",
        "```\n",
        "\n",
        "* File load `upload_colab.tar.gz` to colab session storage"
      ],
      "metadata": {
        "id": "JuFy3l3v2Hr0"
      },
      "id": "JuFy3l3v2Hr0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Setup `NeuralLog` in colab env"
      ],
      "metadata": {
        "id": "bZoynFUb2fL5"
      },
      "id": "bZoynFUb2fL5"
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvfz upload_colab.tar.gz"
      ],
      "metadata": {
        "id": "H95fR7AA2ACK",
        "outputId": "ee9410e2-e34b-4e43-a9fb-32e460750d68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "H95fR7AA2ACK",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralLog/neurallog/\n",
            "NeuralLog/neurallog/data_loader.py\n",
            "NeuralLog/neurallog/models/\n",
            "NeuralLog/neurallog/models/log2vec.py\n",
            "NeuralLog/neurallog/models/logrobust.py\n",
            "NeuralLog/neurallog/models/positional_encodings.py\n",
            "NeuralLog/neurallog/models/transformers.py\n",
            "NeuralLog/neurallog/models/__init__.py\n",
            "NeuralLog/neurallog/utils.py\n",
            "NeuralLog/neurallog/__init__.py\n",
            "NeuralLog/demo/\n",
            "NeuralLog/demo/NeuralLog.py\n",
            "NeuralLog/demo/Transformer_based_Classification.ipynb\n",
            "NeuralLog/requirements_colab_0826.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* get BGL dataset"
      ],
      "metadata": {
        "id": "w1DIjTiy3snX"
      },
      "id": "w1DIjTiy3snX"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "36a722fb",
      "metadata": {
        "id": "36a722fb",
        "outputId": "348c931b-b07f-46bc-f4f7-0dd6d933c06f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-26 06:35:13--  https://zenodo.org/record/3227177/files/BGL.tar.gz\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62936967 (60M) [application/octet-stream]\n",
            "Saving to: ‘BGL.tar.gz’\n",
            "\n",
            "BGL.tar.gz          100%[===================>]  60.02M  3.32MB/s    in 41s     \n",
            "\n",
            "2022-08-26 06:35:56 (1.47 MB/s) - ‘BGL.tar.gz’ saved [62936967/62936967]\n",
            "\n",
            "BGL.log\n"
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/record/3227177/files/BGL.tar.gz && tar -xvzf BGL.tar.gz\n",
        "!mkdir NeuralLog/logs && mv BGL.log NeuralLog/logs/."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/NeuralLog"
      ],
      "metadata": {
        "id": "qmWiP4sq23EI"
      },
      "id": "qmWiP4sq23EI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements_colab_0826.txt"
      ],
      "metadata": {
        "id": "z55ho7BB2N6v"
      },
      "id": "z55ho7BB2N6v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd demo"
      ],
      "metadata": {
        "id": "9XCZJOGA4VKI",
        "outputId": "6cde28dd-7999-4986-8e05-dfa185d97664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9XCZJOGA4VKI",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NeuralLog/demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!time python NeuralLog.py"
      ],
      "metadata": {
        "id": "O0QzhrarU9Dh",
        "outputId": "b8727531-eb05-494b-9620-1eaefc449e07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "O0QzhrarU9Dh",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-26 04:06:21.256899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.4.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n",
            "2022-08-26 04:06:23.422534: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-08-26 04:06:23.425481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-08-26 04:06:23.492402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:23.492990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-08-26 04:06:23.493034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-08-26 04:06:23.557110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-08-26 04:06:23.557197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-08-26 04:06:23.589409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-08-26 04:06:23.609152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-08-26 04:06:23.837878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-08-26 04:06:23.856716: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-08-26 04:06:23.861408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-08-26 04:06:23.861556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:23.862217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:23.862769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-08-26 04:06:23.865410: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-08-26 04:06:23.865540: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-08-26 04:06:23.865662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:23.866203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-08-26 04:06:23.866244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-08-26 04:06:23.866290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-08-26 04:06:23.866313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-08-26 04:06:23.866343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-08-26 04:06:23.866365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-08-26 04:06:23.866385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-08-26 04:06:23.866405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-08-26 04:06:23.866426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-08-26 04:06:23.866496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:23.867101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:23.867657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-08-26 04:06:23.867701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-08-26 04:06:24.591793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-08-26 04:06:24.591852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2022-08-26 04:06:24.591872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2022-08-26 04:06:24.592084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:24.592733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:24.593298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-08-26 04:06:24.593790: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-08-26 04:06:24.593837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13968 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Downloading: 100% 0.99M/0.99M [00:00<00:00, 7.47MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 4.74MB/s]\n",
            "Downloading: 100% 665/665 [00:00<00:00, 678kB/s]\n",
            "Downloading: 100% 475M/475M [00:06<00:00, 72.7MB/s]\n",
            "2022-08-26 04:06:32.977535: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2022-08-26 04:06:33.071988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2022-08-26 04:06:35.170218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "All model checkpoint layers were used when initializing TFGPT2Model.\n",
            "\n",
            "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 3.14MB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 41.8kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 986kB/s]\n",
            "Downloading: 100% 511M/511M [00:11<00:00, 47.9MB/s]\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "Downloading: 100% 878k/878k [00:00<00:00, 7.80MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 6.04MB/s]\n",
            "Downloading: 100% 481/481 [00:00<00:00, 707kB/s]\n",
            "Downloading: 100% 627M/627M [00:10<00:00, 61.7MB/s]\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            "Loading ../logs/BGL.log\n",
            "Loaded 4747963 lines!\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Loading 99.52% - 580 unique logs\n",
            "last train index: 3798360\n",
            "Total failure logs: 17340\n",
            "Total: 150979 instances, 20254 anomaly, 130725 normal\n",
            "Train: 103500 instances, 17250 anomaly, 86250 normal\n",
            "Test: 47479 instances, 3004 anomaly, 44475 normal\n",
            "\n",
            "Number of training samples: 93150 - Number of validating samples: 10350\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 75, 768)]         0         \n",
            "_________________________________________________________________\n",
            "position_embedding (Position (None, 75, 768)           0         \n",
            "_________________________________________________________________\n",
            "transformer_block (Transform (None, 75, 768)           31491584  \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dropout_113 (Dropout)        (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                24608     \n",
            "_________________________________________________________________\n",
            "dropout_114 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 31,516,258\n",
            "Trainable params: 31,516,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1839: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "2022-08-26 04:11:00.436000: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2022-08-26 04:11:00.445056: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "Epoch 1/10\n",
            "363/363 [==============================] - 412s 1s/step - loss: 0.4740 - accuracy: 0.8290 - val_loss: 0.3215 - val_accuracy: 0.8331\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83311, saving model to bgl_transformer.hdf5\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 410s 1s/step - loss: 0.2760 - accuracy: 0.8740 - val_loss: 0.1228 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.83311 to 0.96934, saving model to bgl_transformer.hdf5\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 409s 1s/step - loss: 0.1117 - accuracy: 0.9707 - val_loss: 0.0734 - val_accuracy: 0.9838\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.96934 to 0.98379, saving model to bgl_transformer.hdf5\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 409s 1s/step - loss: 0.0710 - accuracy: 0.9810 - val_loss: 0.0462 - val_accuracy: 0.9852\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.98379 to 0.98516, saving model to bgl_transformer.hdf5\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 409s 1s/step - loss: 0.0428 - accuracy: 0.9870 - val_loss: 0.0274 - val_accuracy: 0.9920\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.98516 to 0.99199, saving model to bgl_transformer.hdf5\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 409s 1s/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0246 - val_accuracy: 0.9928\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.99199 to 0.99277, saving model to bgl_transformer.hdf5\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 409s 1s/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0154 - val_accuracy: 0.9952\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.99277 to 0.99521, saving model to bgl_transformer.hdf5\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 409s 1s/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.0081 - val_accuracy: 0.9976\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.99521 to 0.99756, saving model to bgl_transformer.hdf5\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 409s 1s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0056 - val_accuracy: 0.9982\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.99756 to 0.99824, saving model to bgl_transformer.hdf5\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 409s 1s/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0055 - val_accuracy: 0.9979\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.99824\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1900: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
            "/bin/bash: line 1:   426 Killed                  python NeuralLog.py\n",
            "\n",
            "real\t73m12.237s\n",
            "user\t58m33.120s\n",
            "sys\t3m59.416s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pQwx8F49FcxZ"
      },
      "id": "pQwx8F49FcxZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
